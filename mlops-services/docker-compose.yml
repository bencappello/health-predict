version: '3.8'

services:
  postgres:
    image: postgres:13
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflowdb
    volumes:
      - pgdata:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  airflow-init:
    image: apache/airflow:2.8.1 # Use a specific version
    user: "${AIRFLOW_UID:-50000}" # Ensures files are created with host user permissions
    depends_on:
      - postgres
    environment:
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflowdb
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      # - AIRFLOW__CORE__LOAD_EXAMPLES=False # Optionally disable example DAGs
      # - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True # Optionally expose config in UI
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      # - ./config:/opt/airflow/config # If you have custom airflow.cfg
    entrypoint: /bin/bash
    command: -c "airflow db init && airflow users create --username admin --password admin --firstname Anonymous --lastname User --role Admin --email admin@example.com"

  airflow-webserver:
    image: apache/airflow:2.8.1
    user: "${AIRFLOW_UID:-50000}"
    restart: always
    depends_on:
      - postgres
    ports:
      - "8080:8080"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      # - ./config:/opt/airflow/config
    environment:
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflowdb
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__WEBSERVER__WORKERS=2 # Explicitly set Gunicorn workers
      # - AIRFLOW__CORE__LOAD_EXAMPLES=False
      # - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True
    command: airflow webserver

  airflow-scheduler:
    image: apache/airflow:2.8.1
    user: "${AIRFLOW_UID:-50000}"
    restart: always
    depends_on:
      - postgres
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      # - ./config:/opt/airflow/config
    environment:
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflowdb
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      # - AIRFLOW__CORE__LOAD_EXAMPLES=False
    command: airflow scheduler

  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.11.3 # Use a specific version
    restart: always
    depends_on:
      - postgres
    ports:
      - "5000:5000"
    environment:
      - MLFLOW_BACKEND_STORE_URI=postgresql+psycopg2://airflow:airflow@postgres:5432/mlflowdb 
      # Note: Using the same DB user/pass as Airflow for simplicity here.
      # For production, you'd use a dedicated user/db for MLflow.
      # Ensure 'mlflowdb' database is created in postgres or MLflow will attempt to create it.
      # The postgres service above will create 'airflowdb'. You might need to manually create 'mlflowdb'
      # or configure MLflow/Postgres to allow MLflow to create it.
      # A simple way is to add another init service or manually exec into postgres container once to create it.
    command: >
      bash -c "python3 -m pip install --upgrade pip && \
               python3 -m pip install psycopg2-binary && \
               mlflow server \
                 --host 0.0.0.0 \
                 --port 5000 \
                 --backend-store-uri postgresql+psycopg2://airflow:airflow@postgres:5432/mlflowdb \
                 --default-artifact-root s3://health-predict-mlops-f9ac6509/mlflow-artifacts/"

  jupyterlab:
    image: jupyter/scipy-notebook:latest # Includes pandas, sklearn, matplotlib, seaborn etc.
    user: root # Run as root to install packages and ensure permissions
    ports:
      - "8888:8888"
    volumes:
      - "../:/home/jovyan/work" # Mount the entire project root
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - GRANT_SUDO=yes # Allows sudo in container if needed, useful with user:root
      # - NOTEBOOK_ARGS="--NotebookApp.token='' --NotebookApp.password=''" # Alternative: Disable token/password - use with caution
    working_dir: /home/jovyan/work # Start in the project directory
    command: >
      bash -c "pip install --quiet boto3 && \
               start-notebook.sh --NotebookApp.token='' --NotebookApp.password='' --NotebookApp.ip='0.0.0.0'"
      # Installs boto3 and starts lab listening on all interfaces with no token/password
    networks:
      - default # Connect to the same network as other services

volumes:
  pgdata:

networks:
  default:
    name: mlops_network 