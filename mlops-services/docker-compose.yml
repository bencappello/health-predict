version: '3.8'

services:
  postgres:
    image: postgres:13
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflowdb
      - POSTGRES_MULTIPLE_DATABASES=airflowdb,mlflowdb
    volumes:
      - pgdata:/var/lib/postgresql/data
      - ./postgres-init:/docker-entrypoint-initdb.d
    ports:
      - "5432:5432"

  airflow-init:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    user: "${AIRFLOW_UID:-50000}"
    depends_on:
      - postgres
    environment:
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflowdb
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      # - AIRFLOW__CORE__LOAD_EXAMPLES=False # Optionally disable example DAGs
      # - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True # Optionally expose config in UI
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      # - ./config:/opt/airflow/config # If you have custom airflow.cfg
    entrypoint: /bin/bash
    command: -c "airflow db init && airflow users create --username admin --password admin --firstname Anonymous --lastname User --role Admin --email admin@example.com"

  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    user: "${AIRFLOW_UID:-50000}"
    restart: always
    depends_on:
      - postgres
    ports:
      - "8080:8080"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ../scripts:/home/jovyan/work/scripts
      - ../src:/home/jovyan/work/src
    environment:
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflowdb
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__WEBSERVER__WORKERS=2
      - PYTHONPATH=/home/jovyan/work
    command: airflow webserver

  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    user: "${AIRFLOW_UID:-50000}"
    restart: always
    depends_on:
      - postgres
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ../scripts:/home/jovyan/work/scripts
      - ../src:/home/jovyan/work/src
    environment:
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflowdb
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - PYTHONPATH=/home/jovyan/work
    command: airflow scheduler

  mlflow:
    build:
      context: .
      dockerfile: Dockerfile.mlflow
    restart: always
    depends_on:
      - postgres
    ports:
      - "5000:5000"
    environment:
      - MLFLOW_BACKEND_STORE_URI=postgresql+psycopg2://airflow:airflow@postgres:5432/mlflowdb
    command: >
      --host 0.0.0.0
      --port 5000
      --backend-store-uri postgresql+psycopg2://airflow:airflow@postgres:5432/mlflowdb
      --default-artifact-root s3://health-predict-mlops-f9ac6509/mlflow-artifacts/

  jupyterlab:
    image: jupyter/scipy-notebook:latest # Includes pandas, sklearn, matplotlib, seaborn etc.
    user: root # Run as root to install packages and ensure permissions
    ports:
      - "8888:8888"
    volumes:
      - "../:/home/jovyan/work" # Mount the entire project root
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - GRANT_SUDO=yes # Allows sudo in container if needed, useful with user:root
      # - NOTEBOOK_ARGS="--NotebookApp.token='' --NotebookApp.password=''" # Alternative: Disable token/password - use with caution
    working_dir: /home/jovyan/work # Start in the project directory
    command: >
      bash -c "pip install --upgrade pip && \
               pip install --no-cache-dir -r /home/jovyan/work/scripts/requirements-training.txt && \
               start-notebook.sh --NotebookApp.token='' --NotebookApp.password='' --NotebookApp.ip='0.0.0.0'"
      # Installs dependencies from requirements-training.txt and starts lab
    networks:
      - default # Connect to the same network as other services

volumes:
  pgdata:

networks:
  default:
    name: mlops_network 