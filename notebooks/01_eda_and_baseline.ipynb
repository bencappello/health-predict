{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Health Predict: Initial EDA & Baseline Model\n\nHospital readmissions cost the U.S. healthcare system approximately $26 billion annually, and CMS penalizes hospitals with excessive readmission rates through the Hospital Readmissions Reduction Program. Accurately predicting which patients are likely to be readmitted enables targeted post-discharge interventions, improving outcomes while reducing costs.\n\nThis notebook performs an initial Exploratory Data Analysis (EDA) on the **UCI Diabetes 130-US Hospitals dataset** (1999\u20132008, ~100K inpatient encounters, 50 clinical features) and trains a simple baseline model. The data used here is the initial 20% partition (`initial_train.csv`, `initial_validation.csv`, `initial_test.csv`) created by `split_data.py`; the remaining 80% is reserved as \"future\" batches to simulate data drift in the production pipeline.\n\n**Notebook goals:**\n1. Understand the dataset structure, distributions, and quality issues\n2. Identify key features and patterns relevant to readmission prediction\n3. Clean and preprocess the data for modeling\n4. Establish a baseline model to set a performance lower bound for the production HPO pipeline\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import boto3\n",
    "from io import StringIO\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# MLflow (optional for local EDA, but good practice)\n",
    "# import mlflow\n",
    "# import mlflow.sklearn\n",
    "\n",
    "# Configure pandas display options for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"Initial libraries loaded.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "We use **pandas** and **numpy** for data manipulation, **matplotlib** and **seaborn** for visualization, and **scikit-learn** for preprocessing and baseline modeling. Data is loaded directly from S3 where `split_data.py` partitioned the raw CSV into a 20% initial set (further split into train/validation/test) and an 80% future set used by the Airflow pipeline for drift-aware retraining.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n",
    "\n",
    "- Define S3 bucket and file paths.\n",
    "- Initialize Boto3 client for S3 access.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 Configuration\n",
    "S3_BUCKET_NAME = \"health-predict-mlops-f9ac6509\" # From config_variables.md\n",
    "RAW_DATA_DIR = \"raw_data\"\n",
    "PROCESSED_DATA_DIR = \"processed_data\"\n",
    "\n",
    "INITIAL_TRAIN_KEY = f\"{PROCESSED_DATA_DIR}/initial_train.csv\"\n",
    "INITIAL_VALIDATION_KEY = f\"{PROCESSED_DATA_DIR}/initial_validation.csv\"\n",
    "INITIAL_TEST_KEY = f\"{PROCESSED_DATA_DIR}/initial_test.csv\"\n",
    "FUTURE_DATA_KEY = f\"{PROCESSED_DATA_DIR}/future_data.csv\" # For later use\n",
    "FULL_RAW_DATA_KEY = f\"{RAW_DATA_DIR}/diabetic_data.csv\" # For reference if needed\n",
    "\n",
    "# Initialize S3 client - will use EC2 instance role credentials\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "print(f\"S3 Bucket: {S3_BUCKET_NAME}\")\n",
    "print(f\"Initial Train Data S3 Key: {INITIAL_TRAIN_KEY}\")\n",
    "print(f\"Initial Validation Data S3 Key: {INITIAL_VALIDATION_KEY}\")\n",
    "print(f\"Initial Test Data S3 Key: {INITIAL_TEST_KEY}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Initial Training Data from S3\n",
    "\n",
    "We'll load the `initial_train.csv` for our primary EDA and model training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df_from_s3(bucket, key, s3_client_instance):\n",
    "    \"\"\"Loads a CSV file from S3 into a pandas DataFrame.\"\"\"\n",
    "    try:\n",
    "        response = s3_client_instance.get_object(Bucket=bucket, Key=key)\n",
    "        csv_content = response['Body'].read().decode('utf-8')\n",
    "        df = pd.read_csv(StringIO(csv_content))\n",
    "        print(f\"Successfully loaded '{key}' from S3 bucket '{bucket}'. Shape: {df.shape}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading '{key}' from S3: {e}\")\n",
    "        return None\n",
    "\n",
    "df_train_initial = load_df_from_s3(S3_BUCKET_NAME, INITIAL_TRAIN_KEY, s3_client)\n",
    "\n",
    "if df_train_initial is not None:\n",
    "    print(df_train_initial.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*Next steps will involve detailed EDA, preprocessing, baseline model training, and evaluation.*\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initial Data Exploration (on `df_train_initial`)\n",
    "\n",
    "Let's get a first look at the initial training dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_train_initial is not None:\n",
    "    print(\"\\n--- Data Info ---\")\n",
    "    df_train_initial.info()\n",
    "    \n",
    "    print(\"\\n--- Descriptive Statistics (Numerical) ---\")\n",
    "    print(df_train_initial.describe().T)\n",
    "    \n",
    "    print(\"\\n--- Descriptive Statistics (Categorical) ---\")\n",
    "    print(df_train_initial.describe(include=['object', 'category']).T)\n",
    "    \n",
    "    print(\"\\n--- Missing Values ---\")\n",
    "    missing_values = df_train_initial.isnull().sum()\n",
    "    missing_percentage = (missing_values / len(df_train_initial)) * 100\n",
    "    missing_info = pd.DataFrame({'Missing Count': missing_values, 'Missing Percentage': missing_percentage})\n",
    "    print(missing_info[missing_info['Missing Count'] > 0].sort_values(by='Missing Percentage', ascending=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Key Observations from Initial Exploration\n\n- **Dataset shape**: ~20K rows (20% of the full ~100K dataset), with ~50 columns. Most features are categorical (object type); only a handful are truly numeric.\n- **High-missing columns**: `weight` is >96% missing and practically unusable. `payer_code` (~40% missing) and `medical_specialty` (~49% missing) also have substantial gaps. These are strong candidates for dropping rather than imputation.\n- **Numeric feature distributions**: Features like `number_outpatient`, `number_emergency`, and `number_inpatient` are heavily right-skewed (most values are 0), reflecting that most patients have no prior visits. These \"prior utilization\" features are likely strong readmission predictors.\n- **Identifier columns**: `encounter_id` and `patient_nbr` are identifiers with no predictive value and should be excluded from modeling. Note that `patient_nbr` is not unique per row \u2014 the same patient may have multiple encounters.\n- **Special values**: The dataset uses `?` as a missing-value marker in many string columns. These need to be converted to NaN before analysis.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Target Variable Analysis (`readmitted`)\n",
    "\n",
    "The target variable `readmitted` indicates if a patient was readmitted. Let's examine its distribution.\n",
    "- `<30`: Readmitted within 30 days.\n",
    "- `>30`: Readmitted after 30 days.\n",
    "- `NO`: No readmission.\n",
    "\n",
    "For a binary classification baseline, we might simplify this (e.g., readmitted vs. not readmitted). For now, let's see the raw distribution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_train_initial is not None:\n",
    "    print(\"\\n--- Target Variable Distribution ('readmitted') ---\")\n",
    "    print(df_train_initial['readmitted'].value_counts(normalize=True) * 100)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.countplot(x='readmitted', data=df_train_initial, order=df_train_initial['readmitted'].value_counts().index)\n",
    "    plt.title('Distribution of Target Variable: readmitted')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xlabel('Readmission Status')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Target Distribution Interpretation\n\nThe raw target variable has three classes: **NO** (~54%), **>30** (~35%), and **<30** (~11%). The majority class is \"NO\" (not readmitted), meaning a naive classifier predicting \"NO\" for every patient would achieve ~54% accuracy. This confirms class imbalance.\n\nFor the baseline, we binarize the target into **readmitted** (combining `<30` and `>30`) vs. **not readmitted** (`NO`). The resulting binary split is approximately 54/46, which is more balanced but still slightly skewed. We use `class_weight='balanced'` in the baseline logistic regression to further compensate.\n\nFrom a clinical perspective, the ~11% rate of readmission within 30 days is the most actionable group \u2014 CMS penalties specifically target 30-day readmissions. The production pipeline's binary framing captures all readmissions for simplicity.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Initial Observations & Potential Cleaning Steps:\n",
    "\n",
    "*Based on the `.info()`, `.describe()`, and missing values output, we will note down initial observations here.*\n",
    "\n",
    "*   **Missing Values:** Columns like `weight`, `medical_specialty`, `payer_code` seem to have a high percentage of missing values. We'll need a strategy for these (e.g., imputation, creating a 'missing' category, or dropping if not useful/too sparse).\n",
    "*   **Data Types:** Ensure all columns have appropriate data types. Categorical features might be read as objects and may need explicit conversion to `category` type for efficiency and correct handling in some libraries.\n",
    "*   **Identifier Columns:** Columns like `encounter_id` and `patient_nbr` are likely identifiers and might not be useful as direct features for a predictive model but could be useful for tracking or joining data. `patient_nbr` is important because multiple encounters can belong to the same patient.\n",
    "*   **Categorical Features with Many Levels:** Some categorical columns might have a very large number of unique values (e.g., `diag_1`, `diag_2`, `diag_3`). This could lead to very high dimensionality if one-hot encoded directly. We might need to group them, use target encoding, or select top N categories.\n",
    "*   **Zero Variance / Near Zero Variance:** Check for columns with little to no variation as they won't be predictive.\n",
    "*   **Target Variable Imbalance:** The distribution of `readmitted` might be imbalanced, which could affect model training and evaluation. We might need techniques like oversampling, undersampling, or using appropriate metrics (e.g., F1-score, AUC-ROC).\n",
    "*   **Special Values:** The dataset description mentions 'Not Available', 'Not Mapped', '?' as special values in some columns. These need to be consistently handled (e.g., converted to `NaN`). `split_data.py` does not currently handle this explicitly for all columns during initial load, so it's something to check in the raw data if issues arise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Cleaning & Preprocessing (Initial Pass)\n",
    "\n",
    "Let's start with some basic cleaning based on the observations above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual `?` replacement and missing value handling is performed in Section 4.1 and 4.2 below. This placeholder cell was part of the initial notebook structure; the full cleaning pipeline follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*Further EDA will involve looking at distributions of individual features, relationships between features and the target, and correlations.*\n",
    "--- \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Further Numerical Feature Exploration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_train_initial is not None:\n",
    "    numerical_cols = df_train_initial.select_dtypes(include=np.number).columns.tolist()\n",
    "    # Exclude identifier columns if they were loaded as numbers and not dropped yet\n",
    "    # For now, assume encounter_id and patient_nbr are not in numerical_cols for plotting\n",
    "    # Also excluding obviously categorical IDs that might be num_type by mistake\n",
    "    # A proper list would be derived after confirming true numerical features\n",
    "    plot_numerical_cols = [col for col in numerical_cols if col not in ['encounter_id', 'patient_nbr', \n",
    "                                                                    'admission_type_id', 'discharge_disposition_id', \n",
    "                                                                    'admission_source_id']] # Add other IDs if necessary\n",
    "    \n",
    "    if not plot_numerical_cols:\n",
    "        print(\"No numerical columns selected for plotting after exclusions.\")\n",
    "    else:\n",
    "        print(f\"Plotting histograms for: {plot_numerical_cols}\")\n",
    "        df_train_initial[plot_numerical_cols].hist(bins=30, figsize=(15, 10), layout=(-1, 3))\n",
    "        plt.suptitle(\"Histograms of Numerical Features (Initial Train Data)\")\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"Plotting boxplots for: {plot_numerical_cols}\")\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        for i, col in enumerate(plot_numerical_cols):\n",
    "            plt.subplot((len(plot_numerical_cols) + 2) // 3, 3, i + 1)\n",
    "            sns.boxplot(y=df_train_initial[col])\n",
    "            plt.title(col)\n",
    "        plt.suptitle(\"Boxplots of Numerical Features (Initial Train Data)\")\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Feature Observations\n",
    "\n",
    "- **`time_in_hospital`**: Right-skewed with most stays lasting 1\u20135 days. Longer stays (>10 days) are relatively rare and may indicate more complex cases.\n",
    "- **`num_lab_procedures`**: Approximately normally distributed, centered around 40\u201350 procedures. This reflects the volume of diagnostic testing during each encounter.\n",
    "- **`num_medications`**: Right-skewed, with most patients receiving 10\u201320 medications. Higher medication counts may correlate with disease complexity.\n",
    "- **`number_outpatient`, `number_emergency`, `number_inpatient`**: Extremely skewed \u2014 the vast majority of values are 0. These features count prior healthcare utilization in the year before the encounter. Patients with non-zero values (prior visits) may be at higher readmission risk, making these potentially strong predictors despite their skewed distributions.\n",
    "- **`number_diagnoses`**: Roughly normally distributed, centered around 7\u20139 diagnoses. Higher diagnosis counts indicate greater comorbidity burden.\n",
    "- **Boxplots reveal outliers** in several features, particularly in the utilization counts (`number_outpatient`, `number_emergency`, `number_inpatient`). These extreme values likely represent chronically ill patients with frequent healthcare contact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Further Categorical Feature Exploration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_train_initial is not None:\n",
    "    categorical_cols = df_train_initial.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    # Select a subset of categorical columns for plotting to avoid too many plots\n",
    "    # Exclude high-cardinality features like diag_1, diag_2, diag_3 for now\n",
    "    plot_categorical_cols = [col for col in categorical_cols if df_train_initial[col].nunique() < 25 and col not in ['diag_1', 'diag_2', 'diag_3', 'payer_code', 'medical_specialty']] \n",
    "    \n",
    "    if not plot_categorical_cols:\n",
    "        print(\"No categorical columns selected for plotting after exclusions/nunique filter.\")\n",
    "    else:\n",
    "        print(f\"Plotting barplots for: {plot_categorical_cols}\")\n",
    "        plt.figure(figsize=(18, len(plot_categorical_cols) * 2)) # Adjusted figure size\n",
    "        for i, col in enumerate(plot_categorical_cols):\n",
    "            plt.subplot((len(plot_categorical_cols) + 2) // 3, 3, i + 1)\n",
    "            sns.countplot(y=df_train_initial[col], order=df_train_initial[col].value_counts().index)\n",
    "            plt.title(f'Distribution of {col}')\n",
    "            plt.xlabel('Count')\n",
    "            plt.ylabel(col)\n",
    "        plt.suptitle(\"Distributions of Key Categorical Features (Initial Train Data)\")\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Feature Observations\n",
    "\n",
    "- **`age`**: Distribution is skewed toward older patients, with the 70\u201380 and 60\u201370 brackets being most common. This is consistent with a diabetes-focused dataset, where prevalence increases with age.\n",
    "- **`race`**: Predominantly Caucasian (~75%), followed by African American (~18%). This imbalance reflects the hospital demographics in the dataset and is important context for fairness considerations.\n",
    "- **Medication features** (`metformin`, `glipizide`, `insulin`, etc.): Most show \"No\" or \"Steady\" as dominant values, meaning most patients' diabetes medications were not changed during their hospital stay. Changes in medication (Up/Down) are relatively rare events that may signal clinical decision-making relevant to readmission risk.\n",
    "- **`diabetesMed`**: Predominantly \"Yes,\" confirming nearly all patients in this dataset are on diabetes medication.\n",
    "- **`change`**: Whether the patient's diabetes medications were changed \u2014 roughly evenly split, making this a potentially useful feature.\n",
    "\n",
    "Note: High-cardinality features (`diag_1`, `diag_2`, `diag_3`, `medical_specialty`) and highly-missing features (`payer_code`) are excluded from these plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Cleaning & Preprocessing (Continued)\n",
    "\n",
    "Based on initial EDA, we'll perform cleaning and feature engineering.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Handling '?' and Special Values\n",
    "\n",
    "Many datasets use '?' for missing values. We'll replace these with NaN.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_train_initial is not None:\n",
    "    # Create copies for cleaning to preserve original loaded data if needed for re-runs\n",
    "    df_train_processed = df_train_initial.copy()\n",
    "    \n",
    "    # Replace '?' with NaN\n",
    "    # Iterate through columns because df.replace('?', np.nan) might be slow on large mixed-type DFs\n",
    "    # and can have unintended consequences if '?' is a valid category in some unknown column.\n",
    "    # For this dataset, '?' is widely known as a missing value indicator.\n",
    "    print(\"Replacing '?' with NaN globally...\")\n",
    "    for col in df_train_processed.columns:\n",
    "        if df_train_processed[col].dtype == 'object':\n",
    "            df_train_processed[col] = df_train_processed[col].replace('?', np.nan)\n",
    "    \n",
    "    # Verify '?' is gone from a sample column known to have them\n",
    "    if 'race' in df_train_processed.columns:\n",
    "      print(f\"Value counts for 'race' after replacing '?':\\n{df_train_processed['race'].value_counts(dropna=False)}\")\n",
    "    if 'payer_code' in df_train_processed.columns:\n",
    "        print(f\"Value counts for 'payer_code' after replacing '?':\\n{df_train_processed['payer_code'].value_counts(dropna=False)}\")\n",
    "    if 'medical_specialty' in df_train_processed.columns:\n",
    "        print(f\"Value counts for 'medical_specialty' after replacing '?':\\n{df_train_processed['medical_specialty'].value_counts(dropna=False)}\")\n",
    "else:\n",
    "    print(\"df_train_initial is not loaded. Skipping cleaning.\")\n",
    "    df_train_processed = None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Handling Missing Values (Based on EDA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_train_processed is not None:\n",
    "    print(\"\\n--- Initial Missing Values (Post '?' replacement) ---\")\n",
    "    missing_values_post_q = df_train_processed.isnull().sum()\n",
    "    missing_percentage_post_q = (missing_values_post_q / len(df_train_processed)) * 100\n",
    "    missing_info_post_q = pd.DataFrame({'Missing Count': missing_values_post_q, 'Missing Percentage': missing_percentage_post_q})\n",
    "    print(missing_info_post_q[missing_info_post_q['Missing Count'] > 0].sort_values(by='Missing Percentage', ascending=False))\n",
    "\n",
    "    # Strategy: Drop columns with very high missing percentage for baseline\n",
    "    cols_to_drop_missing = []\n",
    "    if 'weight' in df_train_processed.columns and (df_train_processed['weight'].isnull().sum() / len(df_train_processed)) > 0.9: # Example threshold 90%\n",
    "        cols_to_drop_missing.append('weight')\n",
    "    if 'payer_code' in df_train_processed.columns and (df_train_processed['payer_code'].isnull().sum() / len(df_train_processed)) > 0.4: # Example threshold 40%\n",
    "        cols_to_drop_missing.append('payer_code')\n",
    "    if 'medical_specialty' in df_train_processed.columns and (df_train_processed['medical_specialty'].isnull().sum() / len(df_train_processed)) > 0.4: # Example threshold 40%\n",
    "        cols_to_drop_missing.append('medical_specialty')\n",
    "\n",
    "    if cols_to_drop_missing:\n",
    "        print(f\"\\nDropping columns due to high missing values: {cols_to_drop_missing}\")\n",
    "        df_train_processed.drop(columns=cols_to_drop_missing, inplace=True)\n",
    "    \n",
    "    # For remaining NaNs in categorical features like diag_1, diag_2, diag_3, race:\n",
    "    # Impute with a \"Missing\" category or mode. For baseline, let's use \"Missing\".\n",
    "    # This will be handled by OneHotEncoder later if they are still objects/categories.\n",
    "    # For numerical columns, mean/median imputation might be used, but this dataset has few numerical features with missing values\n",
    "    # after dropping 'weight'.\n",
    "    \n",
    "    # For simplicity in baseline, remaining NaNs in object/category columns will be treated as a separate category by OHE.\n",
    "    # If any numerical columns had NaNs (other than those dropped), they'd need imputation (e.g., median).\n",
    "    # Let's check again after drops:\n",
    "    print(\"\\n--- Missing Values After Dropping High-Missing Columns ---\")\n",
    "    missing_values_after_drop = df_train_processed.isnull().sum()\n",
    "    missing_percentage_after_drop = (missing_values_after_drop / len(df_train_processed)) * 100\n",
    "    missing_info_after_drop = pd.DataFrame({'Missing Count': missing_values_after_drop, 'Missing Percentage': missing_percentage_after_drop})\n",
    "    print(missing_info_after_drop[missing_info_after_drop['Missing Count'] > 0].sort_values(by='Missing Percentage', ascending=False))\n",
    "    \n",
    "    # For this dataset, 'race', 'diag_1', 'diag_2', 'diag_3' might still have NaNs.\n",
    "    # We'll fill them with a placeholder string 'Missing'\n",
    "    for col in ['race', 'diag_1', 'diag_2', 'diag_3']:\n",
    "        if col in df_train_processed.columns and df_train_processed[col].isnull().any():\n",
    "            print(f\"Filling NaNs in '{col}' with 'Missing'\")\n",
    "            df_train_processed[col].fillna('Missing', inplace=True)\n",
    "\n",
    "    # Add filtering for discharge_disposition_id based on data_summary.md (removing expired/hospice)\n",
    "    # Typical codes: Expired (11, 19, 20, 21), Hospice (13, 14)\n",
    "    # These should be confirmed if an ID mapping file is available. Assuming these are standard for now.\n",
    "    expired_ids = [11, 19, 20, 21]\n",
    "    hospice_ids = [13, 14]\n",
    "    discharge_ids_to_remove = expired_ids + hospice_ids\n",
    "\n",
    "    if 'discharge_disposition_id' in df_train_processed.columns:\n",
    "        initial_rows = len(df_train_processed)\n",
    "        df_train_processed = df_train_processed[~df_train_processed['discharge_disposition_id'].isin(discharge_ids_to_remove)]\n",
    "        rows_removed = initial_rows - len(df_train_processed)\n",
    "        print(f\"Removed {rows_removed} rows due to discharge to hospice or expired.\")\n",
    "    else:\n",
    "        print(\"Warning: 'discharge_disposition_id' column not found. Skipping hospice/expired filtering.\")\n",
    "\n",
    "\n",
    "    print(\"\\n--- Final Check for Missing Values ---\")\n",
    "    print(df_train_processed.isnull().sum().sum(), \"total missing values remaining.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Value Strategy Rationale\n",
    "\n",
    "Our approach to missing values follows a tiered strategy:\n",
    "\n",
    "- **`weight` (>96% missing)**: Dropped. With virtually no data, imputation would introduce noise rather than signal.\n",
    "- **`payer_code` (~40% missing)**: Dropped. Insurance type has uncertain predictive value for readmission, and the high missingness makes it unreliable.\n",
    "- **`medical_specialty` (~49% missing)**: Dropped. High cardinality (73+ specialties) combined with near-50% missingness makes it impractical for this baseline.\n",
    "- **Remaining NaN in `race`, `diag_1`, `diag_2`, `diag_3`**: Filled with \"Missing\" to preserve the missingness signal as an explicit category. Whether a diagnosis code is missing may itself be informative.\n",
    "- **Expired/hospice patient filtering**: Patients who expired during their stay or were discharged to hospice (disposition IDs 11, 13, 14, 19, 20, 21) are removed. These patients cannot be \"readmitted,\" and including them would contaminate the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Feature Engineering\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_train_processed is not None:\n",
    "    # 1. Simplify Target Variable 'readmitted'\n",
    "    #    NO -> 0 (Not Readmitted)\n",
    "    #    <30, >30 -> 1 (Readmitted)\n",
    "    print(\"\\n--- Simplifying Target Variable 'readmitted' ---\")\n",
    "    df_train_processed['readmitted_binary'] = df_train_processed['readmitted'].apply(lambda x: 0 if x == 'NO' else 1)\n",
    "    print(df_train_processed['readmitted_binary'].value_counts(normalize=True))\n",
    "    \n",
    "    # 2. Process 'age' column: '[70-80)' -> 75 (midpoint) or ordinal\n",
    "    # Using ordinal for simplicity and to maintain order\n",
    "    print(\"\\n--- Processing 'age' column ---\")\n",
    "    if 'age' in df_train_processed.columns:\n",
    "        age_mapping = {\n",
    "            '[0-10)': 0, '[10-20)': 1, '[20-30)': 2, '[30-40)': 3, '[40-50)': 4,\n",
    "            '[50-60)': 5, '[60-70)': 6, '[70-80)': 7, '[80-90)': 8, '[90-100)': 9\n",
    "        }\n",
    "        df_train_processed['age_ordinal'] = df_train_processed['age'].map(age_mapping)\n",
    "        print(df_train_processed[['age', 'age_ordinal']].head())\n",
    "    \n",
    "    # 3. Drop original 'readmitted' and 'age' columns, and identifiers\n",
    "    cols_to_drop_engineered = ['readmitted', 'age', 'encounter_id', 'patient_nbr']\n",
    "    # Also drop diag_1, diag_2, diag_3 for baseline simplicity due to high cardinality and complexity of encoding them properly\n",
    "    # A more advanced approach would involve feature engineering on these.\n",
    "    cols_to_drop_engineered.extend(['diag_1', 'diag_2', 'diag_3'])\n",
    "\n",
    "    existing_cols_to_drop = [col for col in cols_to_drop_engineered if col in df_train_processed.columns]\n",
    "    print(f\"\\nDropping columns: {existing_cols_to_drop}\")\n",
    "    df_train_processed.drop(columns=existing_cols_to_drop, inplace=True)\n",
    "    \n",
    "    print(\"\\n--- DataFrame after initial Feature Engineering ---\")\n",
    "    print(df_train_processed.head())\n",
    "    df_train_processed.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering Rationale\n",
    "\n",
    "- **Binary target (`readmitted_binary`)**: Simplifies the problem from 3-class to binary classification. Clinically, any readmission (whether within 30 days or later) is undesirable, and the binary framing makes the model actionable for discharge planning.\n",
    "- **Age ordinal encoding**: Converts 10-year bracket strings (e.g., `[70-80)`) into ordinal integers (0\u20139). This preserves the natural age ordering while being compatible with StandardScaler. The production pipeline uses the same mapping.\n",
    "- **Dropping `diag_1`, `diag_2`, `diag_3`**: These ICD-9 diagnosis codes have 700+ unique values each. One-hot encoding them would create thousands of sparse columns and dominate the feature space. The production pipeline retains them (they are handled differently via the feature engineering module), but for this baseline they are excluded for simplicity.\n",
    "- **Dropping identifiers** (`encounter_id`, `patient_nbr`): Not predictive features. Patient ID could enable patient-level feature engineering in future work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preprocessing for Modeling\n",
    "\n",
    "We apply a `ColumnTransformer` pipeline with two branches:\n",
    "- **StandardScaler** for numeric features \u2014 centers and scales to zero mean and unit variance, which helps logistic regression converge faster.\n",
    "- **OneHotEncoder** for categorical features \u2014 converts string categories into binary indicator columns. We use `handle_unknown='ignore'` to gracefully handle categories in validation/test that were unseen during training, and `drop='first'` to avoid multicollinearity (important for logistic regression's coefficient interpretability).\n",
    "\n",
    "Note that columns like `admission_type_id`, `discharge_disposition_id`, and `admission_source_id` are numeric IDs representing categories (not continuous values), so they are treated as categorical despite being integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_train_processed is not None:\n",
    "    y_train = df_train_processed['readmitted_binary']\n",
    "    X_train = df_train_processed.drop(columns=['readmitted_binary'])\n",
    "\n",
    "    # Identify categorical and numerical columns\n",
    "    # Ensure 'id' columns that are actually categorical are treated as such\n",
    "    # For this dataset, many columns like 'admission_type_id' are categorical despite being numbers\n",
    "    # A full list based on dataset description would be ideal. For now, an approximation:\n",
    "    potential_categorical_ids = ['admission_type_id', 'discharge_disposition_id', 'admission_source_id'] # Add others if known\n",
    "    \n",
    "    categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    for col_id in potential_categorical_ids:\n",
    "        if col_id in X_train.columns and X_train[col_id].dtype != 'object' and X_train[col_id].dtype != 'category':\n",
    "            if X_train[col_id].nunique() < 30: # Heuristic for ID-like categoricals\n",
    "                 categorical_features.append(col_id)\n",
    "                 X_train[col_id] = X_train[col_id].astype('category')\n",
    "\n",
    "\n",
    "    numerical_features = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "    # Remove any numerical features that were re-classified as categorical (like age_ordinal if we want to OHE it, but we'll scale it)\n",
    "    # or actual categorical_ids that were numeric\n",
    "    numerical_features = [col for col in numerical_features if col not in categorical_features]\n",
    "    if 'age_ordinal' in numerical_features: # Keep age_ordinal as numerical for scaling\n",
    "        pass\n",
    "    \n",
    "    # Ensure no overlap and all columns are covered\n",
    "    categorical_features = list(set(categorical_features)) # Deduplicate\n",
    "    processed_cols = set(categorical_features + numerical_features)\n",
    "    all_cols = set(X_train.columns)\n",
    "    if processed_cols != all_cols:\n",
    "        print(f\"Warning: Column mismatch. Untracked columns: {all_cols - processed_cols}\")\n",
    "        print(f\"All: {all_cols}, Processed: {processed_cols}\")\n",
    "        # For any remaining, classify as categorical if object, else numerical\n",
    "        for rem_col in (all_cols - processed_cols):\n",
    "            if X_train[rem_col].dtype == 'object':\n",
    "                categorical_features.append(rem_col)\n",
    "            else:\n",
    "                numerical_features.append(rem_col)\n",
    "        categorical_features = list(set(categorical_features))\n",
    "        numerical_features = list(set(numerical_features) - set(categorical_features))\n",
    "\n",
    "\n",
    "    print(f\"\\nIdentified Numerical Features: {numerical_features}\")\n",
    "    print(f\"Identified Categorical Features: {categorical_features}\")\n",
    "\n",
    "    # Create preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore', drop='first'), categorical_features)\n",
    "        ], \n",
    "        remainder='passthrough' # Should be empty if all cols are covered\n",
    "    )\n",
    "\n",
    "    # Fit and transform the training data\n",
    "    print(\"\\nFitting preprocessor and transforming training data...\")\n",
    "    X_train_prepared = preprocessor.fit_transform(X_train)\n",
    "    \n",
    "    # Get feature names after OHE for creating a DataFrame (optional, but good for inspection)\n",
    "    try:\n",
    "        ohe_feature_names = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
    "        all_feature_names = numerical_features + ohe_feature_names.tolist()\n",
    "        X_train_prepared_df = pd.DataFrame(X_train_prepared.toarray() if hasattr(X_train_prepared, \"toarray\") else X_train_prepared, columns=all_feature_names) # .toarray() for sparse matrix\n",
    "        print(f\"Training data transformed. Shape: {X_train_prepared_df.shape}\")\n",
    "        print(X_train_prepared_df.head())\n",
    "    except Exception as e:\n",
    "        print(f\"Could not get OHE feature names or create DataFrame: {e}\")\n",
    "        print(f\"Training data transformed (sparse matrix). Shape: {X_train_prepared.shape}\")\n",
    "\n",
    "\n",
    "    # Preprocess Validation and Test data\n",
    "    print(\"\\nLoading and preprocessing validation and test data...\")\n",
    "    df_val_initial = load_df_from_s3(S3_BUCKET_NAME, INITIAL_VALIDATION_KEY, s3_client)\n",
    "    df_test_initial = load_df_from_s3(S3_BUCKET_NAME, INITIAL_TEST_KEY, s3_client)\n",
    "\n",
    "    X_val_prepared = None\n",
    "    y_val = None\n",
    "    X_test_prepared = None\n",
    "    y_test = None\n",
    "\n",
    "    if df_val_initial is not None:\n",
    "        df_val_processed = df_val_initial.copy()\n",
    "        for col in df_val_processed.columns: # Replace '?'\n",
    "            if df_val_processed[col].dtype == 'object':\n",
    "                df_val_processed[col] = df_val_processed[col].replace('?', np.nan)\n",
    "        if cols_to_drop_missing: # Drop same high-missing columns\n",
    "            df_val_processed.drop(columns=[col for col in cols_to_drop_missing if col in df_val_processed.columns], inplace=True)\n",
    "        for col in ['race', 'diag_1', 'diag_2', 'diag_3']: # Fill NaNs\n",
    "            if col in df_val_processed.columns: df_val_processed[col].fillna('Missing', inplace=True)\n",
    "        \n",
    "        # Apply discharge disposition filtering\n",
    "        if 'discharge_disposition_id' in df_val_processed.columns:\n",
    "            df_val_processed = df_val_processed[~df_val_processed['discharge_disposition_id'].isin(discharge_ids_to_remove)]\n",
    "            print(f\"Validation data rows after hospice/expired filter: {len(df_val_processed)}\")\n",
    "\n",
    "        df_val_processed['readmitted_binary'] = df_val_processed['readmitted'].apply(lambda x: 0 if x == 'NO' else 1)\n",
    "        if 'age' in df_val_processed.columns:\n",
    "             df_val_processed['age_ordinal'] = df_val_processed['age'].map(age_mapping)\n",
    "        existing_cols_to_drop_val = [col for col in cols_to_drop_engineered if col in df_val_processed.columns]\n",
    "        df_val_processed.drop(columns=existing_cols_to_drop_val, inplace=True)\n",
    "        \n",
    "        y_val = df_val_processed['readmitted_binary']\n",
    "        X_val = df_val_processed.drop(columns=['readmitted_binary'])\n",
    "        for col_id in potential_categorical_ids: # Ensure cat type for IDs\n",
    "            if col_id in X_val.columns and X_val[col_id].dtype != 'object' and X_val[col_id].dtype != 'category':\n",
    "                 X_val[col_id] = X_val[col_id].astype('category')\n",
    "        \n",
    "        X_val_prepared = preprocessor.transform(X_val)\n",
    "        print(f\"Validation data transformed. Shape: {X_val_prepared.shape}\")\n",
    "\n",
    "    if df_test_initial is not None:\n",
    "        df_test_processed = df_test_initial.copy()\n",
    "        for col in df_test_processed.columns: # Replace '?'\n",
    "             if df_test_processed[col].dtype == 'object':\n",
    "                df_test_processed[col] = df_test_processed[col].replace('?', np.nan)\n",
    "        if cols_to_drop_missing: # Drop same high-missing columns\n",
    "            df_test_processed.drop(columns=[col for col in cols_to_drop_missing if col in df_test_processed.columns], inplace=True)\n",
    "        for col in ['race', 'diag_1', 'diag_2', 'diag_3']: # Fill NaNs\n",
    "            if col in df_test_processed.columns: df_test_processed[col].fillna('Missing', inplace=True)\n",
    "\n",
    "        # Apply discharge disposition filtering\n",
    "        if 'discharge_disposition_id' in df_test_processed.columns:\n",
    "            df_test_processed = df_test_processed[~df_test_processed['discharge_disposition_id'].isin(discharge_ids_to_remove)]\n",
    "            print(f\"Test data rows after hospice/expired filter: {len(df_test_processed)}\")\n",
    "\n",
    "        df_test_processed['readmitted_binary'] = df_test_processed['readmitted'].apply(lambda x: 0 if x == 'NO' else 1)\n",
    "        if 'age' in df_test_processed.columns:\n",
    "            df_test_processed['age_ordinal'] = df_test_processed['age'].map(age_mapping)\n",
    "        existing_cols_to_drop_test = [col for col in cols_to_drop_engineered if col in df_test_processed.columns]\n",
    "        df_test_processed.drop(columns=existing_cols_to_drop_test, inplace=True)\n",
    "\n",
    "        y_test = df_test_processed['readmitted_binary']\n",
    "        X_test = df_test_processed.drop(columns=['readmitted_binary'])\n",
    "        for col_id in potential_categorical_ids: # Ensure cat type for IDs\n",
    "            if col_id in X_test.columns and X_test[col_id].dtype != 'object' and X_test[col_id].dtype != 'category':\n",
    "                 X_test[col_id] = X_test[col_id].astype('category')\n",
    "\n",
    "        X_test_prepared = preprocessor.transform(X_test)\n",
    "        print(f\"Test data transformed. Shape: {X_test_prepared.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train Baseline Model (Logistic Regression)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = None\n",
    "if X_train_prepared is not None and y_train is not None:\n",
    "    print(\"\\n--- Training Baseline Model (Logistic Regression) ---\")\n",
    "    baseline_model = LogisticRegression(solver='liblinear', random_state=42, class_weight='balanced') # class_weight for imbalance\n",
    "    baseline_model.fit(X_train_prepared, y_train)\n",
    "    print(\"Baseline model trained.\")\n",
    "else:\n",
    "    print(\"Training data not prepared. Skipping model training.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Choice Rationale\n",
    "\n",
    "We use **Logistic Regression** as the baseline for several reasons:\n",
    "- It is simple, fast, and highly interpretable \u2014 ideal for establishing a performance floor.\n",
    "- `class_weight='balanced'` automatically adjusts class weights inversely proportional to class frequencies, compensating for the slight target imbalance.\n",
    "- The `liblinear` solver handles both L1 and L2 regularization and works well with small-to-medium datasets.\n",
    "\n",
    "The production pipeline trains **XGBoost** with Ray Tune hyperparameter optimization (ASHA scheduler), exploring learning rate, tree depth, regularization, and subsampling parameters. This baseline provides a comparison point to quantify the improvement from HPO-tuned ensemble methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate Baseline Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if baseline_model is not None and X_test_prepared is not None and y_test is not None:\n",
    "    print(\"\\n--- Evaluating Baseline Model on Test Set ---\")\n",
    "    y_pred_test = baseline_model.predict(X_test_prepared)\n",
    "    \n",
    "    print(\"\\nClassification Report (Test Set):\")\n",
    "    print(classification_report(y_test, y_pred_test))\n",
    "    \n",
    "    print(\"Accuracy Score (Test Set):\")\n",
    "    print(accuracy_score(y_test, y_pred_test))\n",
    "    \n",
    "    print(\"\\nConfusion Matrix (Test Set):\")\n",
    "    cm = confusion_matrix(y_test, y_pred_test)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=['Not Readmitted', 'Readmitted'], \n",
    "                yticklabels=['Not Readmitted', 'Readmitted'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix - Test Set')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Model not trained or test data not prepared. Skipping evaluation.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Results Interpretation\n",
    "\n",
    "With a binary target split of approximately 54/46, a random-chance classifier would achieve ~54% accuracy. The logistic regression baseline should exceed this threshold, confirming that the features carry genuine predictive signal.\n",
    "\n",
    "**Key metrics to consider:**\n",
    "- **Recall (sensitivity)** is arguably the most important metric in this clinical context \u2014 failing to identify a patient at risk of readmission (false negative) means a missed intervention opportunity. Higher recall means fewer missed at-risk patients.\n",
    "- **Precision** reflects how many flagged patients are truly at risk. Lower precision means more unnecessary interventions, but this is generally preferable to missing at-risk patients.\n",
    "- **Confusion matrix**: The off-diagonal cells reveal the error patterns. False negatives (bottom-left) represent patients who were readmitted but predicted as \"not readmitted\" \u2014 the costliest errors clinically.\n",
    "\n",
    "This baseline establishes a performance lower bound. The production pipeline uses XGBoost with Ray Tune hyperparameter optimization and achieves significantly higher AUC (~0.64+), demonstrating the value of more sophisticated modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusions & Connection to Production Pipeline\n",
    "\n",
    "### EDA Summary\n",
    "- The UCI Diabetes dataset is predominantly categorical, with significant missing data in `weight` (>96%), `medical_specialty` (~49%), and `payer_code` (~40%).\n",
    "- The target variable is moderately imbalanced (~54% not readmitted, ~46% readmitted after binarization).\n",
    "- Prior healthcare utilization features (`number_outpatient`, `number_emergency`, `number_inpatient`) are extremely right-skewed but likely carry strong predictive signal.\n",
    "- The patient population skews older (60\u201380 age range dominant) and is predominantly Caucasian, consistent with diabetes demographics.\n",
    "\n",
    "### How EDA Findings Informed the Production Pipeline\n",
    "- **Drift detection excludes `diag_1/2/3`**: These high-cardinality ICD-9 codes always show spurious drift in chi-squared tests. The EDA confirmed their 700+ unique values make them problematic for statistical comparison, so they are excluded from drift analysis.\n",
    "- **Missing value strategy**: The production `clean_data()` function drops the same three columns identified here (`weight`, `payer_code`, `medical_specialty`) and fills remaining NaN with \"Unknown\" \u2014 matching the pattern established in this EDA.\n",
    "- **Binary target**: The production pipeline uses the same `readmitted_binary` encoding established here, driven by clinical simplicity and CMS relevance.\n",
    "- **Cumulative learning**: This baseline uses only the initial 20% partition. The production pipeline progressively incorporates future batches (cumulative learning), allowing the model to adapt to distributional shifts identified by drift detection.\n",
    "\n",
    "### Baseline Limitations\n",
    "- Simple feature engineering (ordinal age, dropped diagnosis codes, no interaction terms)\n",
    "- Only logistic regression \u2014 no ensemble methods or hyperparameter tuning\n",
    "- No patient-level deduplication (same patient may appear multiple times)\n",
    "- `class_weight='balanced'` is a basic approach to imbalance; production could benefit from SMOTE or cost-sensitive learning\n",
    "\n",
    "### From Baseline to Production\n",
    "The production pipeline addresses these limitations with XGBoost trained via Ray Tune HPO (ASHA scheduler), a proper quality gate that prevents regression, and drift-gated retraining that ensures the model stays current as data distributions shift across batches."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}